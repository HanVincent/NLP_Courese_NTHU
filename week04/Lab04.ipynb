{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, re\n",
    "from pprint import pprint\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "count = dict()\n",
    "count_c = defaultdict(lambda: 0)\n",
    "for line in open('count_1edit.txt', 'r', encoding='utf8'):\n",
    "    wc, num = line.strip().split('\\t')\n",
    "    w, c = wc.split('|')\n",
    "    count[(w, c)] = int(num)\n",
    "    count_c[c] += int(num)\n",
    "Ncount = Counter(count.values())\n",
    "\n",
    "Nall = len(count.keys())\n",
    "N0 = 26*26*26*26+2*26*26*26+26*26 - Nall\n",
    "Nr = [ N0 if r == 0 else Ncount[r] for r in range(12) ]\n",
    "\n",
    "def smooth(count, r=10):\n",
    "    if count <= r:\n",
    "        return (count+1)*Nr[count+1] / Nr[count]\n",
    "    else:\n",
    "        return count\n",
    "\n",
    "def Pedit(w, c):\n",
    "    if (w, c) not in count and count_c[c] > 0:\n",
    "        return smooth(0) / count_c[c]\n",
    "    if count_c[c] > 0:\n",
    "        return smooth(count[(w, c)]) / count_c[c]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "# WORDS = Counter(open('big.txt').read().split())\n",
    "\n",
    "def Pw(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    states = [ ('', word, 0, Pw(word), 1) ]\n",
    "    for i in range(len(word)):\n",
    "        # print(i, states[:3])\n",
    "        STATES = [ s for state in states for s in next_states(state) ]\n",
    "        states = sorted(STATES, key=lambda x: x[2])\n",
    "\n",
    "        unique, new_states = set(), []\n",
    "        for state in states:\n",
    "            if state[0] + state[1] in unique: continue\n",
    "\n",
    "            unique.add(state[0] + state[1])\n",
    "            new_states.append(state)\n",
    "        states = new_states\n",
    "        states = sorted(states, key=lambda x: P(x[3], x[4]), reverse=True) [:500]# [:MAXBEAM]\n",
    "    return states[:10]\n",
    "\n",
    "def next_states(state):\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    L, R, edit, prob, ped = state\n",
    "    R0, R1 = R[0], R[1:]\n",
    "    if edit == 2: return [( L + R0, R1, edit, prob, ped*0.8 )]\n",
    "    noedit    = [( L + R0, R1, edit, prob, ped*0.8 )]\n",
    "    delete    = [( L, R1, edit+1, Pw(L + R1), ped * Pedit(L[-1]+R0, L[-1]))]  if len(L) > 0 else []\n",
    "    insert    = [( L + R0 + c, R1, edit+1, Pw(L + R0 + c + R1), ped * Pedit(R0, R0 + c) ) for c in letters]\n",
    "    replace   = [( L + c, R1, edit+1, Pw(L + c + R1), ped * Pedit(R0, c) ) for c in letters]\n",
    "    transpose = [( L[:-1] + R0 + L[-1], R1, edit+1, Pw(L[:-1] + R0 + L[-1] + R1), ped * Pedit(L[-1]+R0, R0+L[-1]) )] if len(L) > 1 else []\n",
    "    return set(noedit + delete + replace + insert + transpose)\n",
    "\n",
    "'''Combining channel probability with word probability to score states'''\n",
    "def P(pw, pedit):\n",
    "    return pw*pedit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"http://api.netspeak.org/netspeak3/search?query=%s\"\n",
    "\n",
    "class NetSpeak:\n",
    "    def __init__(self):\n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (compatible; MSIE 5.5; Windows NT)'}\n",
    "        self.page = None\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def __getPageContent(self, url):\n",
    "        return requests.get(url, headers=self.headers).text\n",
    "        # return self.opener.open(url).read()\n",
    "\n",
    "    def __rolling(self, url, maxfreq=None):\n",
    "        if maxfreq:\n",
    "            webdata = self.__getPageContent(url + \"&maxfreq=%s\" % maxfreq)\n",
    "        else:\n",
    "            webdata = self.__getPageContent(url)\n",
    "        if webdata:\n",
    "            # webdata = webdata.decode('utf-8')\n",
    "            results = [data.split('\\t') for data in webdata.splitlines()]\n",
    "            results = [(data[2], float(data[1])) for data in results]\n",
    "            lastFreq = int(results[-1][1])\n",
    "            if lastFreq != maxfreq:\n",
    "                return results + self.__rolling(url, lastFreq)\n",
    "            else:\n",
    "                return []\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def search(self, query):\n",
    "        if query in self.dictionary: return self.dictionary[query]\n",
    "        \n",
    "        queries = query.lower().split()\n",
    "        new_query = []\n",
    "        for token in queries:\n",
    "            if token.count('|') > 0:\n",
    "                new_query.append('[+{0}+]'.format('+'.join(token.split('|'))))\n",
    "            elif token == '*':\n",
    "                new_query.append('?')\n",
    "            else:\n",
    "                new_query.append(token)\n",
    "        new_query = '+'.join(new_query)\n",
    "        url = API_URL % (new_query.replace(' ', '+'))\n",
    "        self.dictionary[query] = self.__rolling(url)\n",
    "        return self.dictionary[query]\n",
    "    \n",
    "SE = NetSpeak() # singleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusable = dict([line.strip().split('\\t') for line in open('lab4.confusables.txt', 'r', encoding='utf8')])\n",
    "\n",
    "def get_trigrams(tokens):\n",
    "    return [tokens[i:i+3] for i in range(len(tokens) - 2)]\n",
    "\n",
    "def get_lowest_tri(tokens):\n",
    "    trigrams, pairs = get_trigrams(tokens), [] # (index, count, trigram)\n",
    "    for i, tri in enumerate(trigrams):\n",
    "        res = SE.search(' '.join(tri))\n",
    "        if res:\n",
    "            pairs.append((i, res[0][1], tri))\n",
    "        else:\n",
    "            pairs.append((i, 0, tri))\n",
    "\n",
    "    minimum = min(pairs, key=lambda x: x[1])[1]\n",
    "    pairs = [p for p in pairs if p[1] == minimum]\n",
    "    \n",
    "    lowest_pair = pairs[0]\n",
    "    lowest_start = lowest_pair[0]\n",
    "    \n",
    "    return lowest_pair, lowest_start\n",
    "\n",
    "def get_max_sent(tokens, lowest_start):\n",
    "    # (sent, error_word, correct_token, can_tokens, count)\n",
    "    best = (None, None, None, None, -math.inf)\n",
    "    \n",
    "    for i in range(lowest_start, lowest_start + 3):\n",
    "        can_tokens = [can[0] for can in correction(tokens[i])] + ([confusable[tokens[i]]] if tokens[i] in confusable else [])\n",
    "        for c in can_tokens: # get correction candidates (a word)\n",
    "            count = 1.0\n",
    "            sent = tokens[:i] + [c] + tokens[i+1:]\n",
    "            trigrams = get_trigrams(sent)\n",
    "        \n",
    "            for tri in trigrams:\n",
    "                res = SE.search(' '.join(tri))\n",
    "                count *= res[0][1] if res else 0\n",
    "\n",
    "            best = (sent, tokens[i], c, can_tokens, count) if count > best[-1] else best\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ 1 ===================\n",
      "Error: strang\n",
      "Candidates: ['strange', 'strong', 'staring', 'sprang', 'string', 'strings', 'spring', 'storing', 'strand', 'stand']\n",
      "Correction: strange\n",
      "I felt very strang -> I felt very strange (correct: I felt very strange )\n",
      "hits = 1\n",
      "\n",
      "================ 2 ===================\n",
      "Error: brake\n",
      "Candidates: ['break', 'broken', 'broke', 'brake', 'bark', 'bracket', 'baker', 'breaks', 'braced', 'barked', 'break']\n",
      "Correction: break\n",
      "at brake time -> at break time (correct: at break time )\n",
      "hits = 2\n",
      "\n",
      "================ 3 ===================\n",
      "Error: brack\n",
      "Candidates: ['black', 'back', 'branch', 'brick', 'bricks', 'breach', 'brisk', 'block', 'pack', 'backs']\n",
      "Correction: block\n",
      "when the brack was finished -> when the block was finished (correct: when the break was finished )\n",
      "hits = 2\n",
      "\n",
      "================ 4 ===================\n",
      "Error: weanter\n",
      "Candidates: ['water', 'wanted', 'winter', 'wander', 'weather', 'walter', 'venter', 'waiter', 'decanter', 'weaned']\n",
      "Correction: water\n",
      "in the weanter when it was snowing -> in the water when it was snowing (correct: in the winter when it was snowing )\n",
      "hits = 2\n",
      "\n",
      "================ 5 ===================\n",
      "Error: gost\n",
      "Candidates: ['just', 'most', 'ghost', 'got', 'cost', 'gross', 'must', 'get', 'coast', 'guest']\n",
      "Correction: most\n",
      "I thought it was a gost -> I thought it was a most (correct: I thought it was a ghost )\n",
      "hits = 2\n",
      "\n",
      "================ 6 ===================\n",
      "Error: expect\n",
      "Candidates: ['expect', 'expects', 'aspect', 'except', 'expert', 'export', 'extent', 'experts', 'expend', 'expel']\n",
      "Correction: except\n",
      "everything expect the houses -> everything except the houses (correct: everything except the houses )\n",
      "hits = 3\n",
      "\n",
      "================ 7 ===================\n",
      "Error: steped\n",
      "Candidates: ['stepped', 'stooped', 'striped', 'stupid', 'stopped', 'shaped', 'speed', 'stephen', 'stated', 'stared']\n",
      "Correction: stepped\n",
      "when I first steped -> when I first stepped (correct: when I first stepped )\n",
      "hits = 4\n",
      "\n",
      "================ 8 ===================\n",
      "Error: exclation\n",
      "Candidates: ['exclusion', 'excavation', 'exaltation', 'exultation', 'exudation', 'exception', 'expiation', 'elation', 'emulation', 'epilation']\n",
      "Correction: exception\n",
      "I was on an exclation -> I was on an exception (correct: I was on an escalator )\n",
      "hits = 4\n",
      "\n",
      "================ 9 ===================\n",
      "Error: noicey\n",
      "Candidates: ['notice', 'noticed', 'noise', 'nicely', 'notices', 'voice', 'novices', 'voices', 'novice', 'nice']\n",
      "Correction: noticed\n",
      "I noicey that I was on this thing -> I noticed that I was on this thing (correct: I noticed that I was on this thing )\n",
      "hits = 5\n",
      "\n",
      "================ 10 ===================\n",
      "Error: fance\n",
      "Candidates: ['france', 'face', 'fancy', 'fancies', 'faces', 'fancied', 'fence', 'fiancee', 'faced', 'force']\n",
      "Correction: fence\n",
      "through the fance -> through the fence (correct: through the fence )\n",
      "hits = 6\n",
      "\n",
      "================ 11 ===================\n",
      "Error: kille\n",
      "Candidates: ['killed', 'kill', 'hill', 'till', 'killer', 'tilled', 'hills', 'kindle', 'kills', 'tiller']\n",
      "Correction: killed\n",
      "the hunters kille them -> the hunters killed them (correct: the hunters kill them )\n",
      "hits = 6\n",
      "\n",
      "================ 12 ===================\n",
      "Error: nerrow\n",
      "Candidates: ['narrow', 'marrow', 'morrow', 'narrows', 'sorrow', 'borrow', 'neuro', 'terror', 'negro', 'furrow']\n",
      "Correction: narrow\n",
      "they kill birds with their nerrow -> they kill birds with their narrow (correct: they kill birds with their arrow )\n",
      "hits = 6\n",
      "\n",
      "================ 13 ===================\n",
      "Error: depe\n",
      "Candidates: ['deep', 'type', 'keep', 'depth', 'were', 'dip', 'weep', 'debt', 'pipe', 'kept']\n",
      "Correction: deep\n",
      "make a depe hole -> make a deep hole (correct: make a deep hole )\n",
      "hits = 7\n",
      "\n",
      "================ 14 ===================\n",
      "Error: gardon\n",
      "Candidates: ['garden', 'gardens', 'gordon', 'pardon', 'carbon', 'cordon', 'garcon', 'pardons', 'carron', 'gallon']\n",
      "Correction: garden\n",
      "to tidy up his gardon -> to tidy up his garden (correct: to tidy up his garden )\n",
      "hits = 8\n",
      "\n",
      "================ 15 ===================\n",
      "Error: belu\n",
      "Candidates: ['below', 'blue', 'bell', 'blew', 'ball', 'bill', 'begun', 'be', 'blur', 'well']\n",
      "Correction: blew\n",
      "the wind belu the leaves -> the wind blew the leaves (correct: the wind blew the leaves )\n",
      "hits = 9\n",
      "\n",
      "================ 16 ===================\n",
      "Error: Mr\n",
      "Candidates: ['mr', 'mrs', 'my', 'me', 'm', 'or', 'mb', 'ma', 'of', 'are']\n",
      "Correction: mr\n",
      "Mr J. was very angray -> mr J. was very angray (correct: Mr J. was very angry )\n",
      "hits = 9\n",
      "\n",
      "================ 17 ===================\n",
      "Error: leavs\n",
      "Candidates: ['leaves', 'laws', 'leave', 'least', 'leads', 'lads', 'leaps', 'loans', 'means', 'learns']\n",
      "Correction: leaves\n",
      "garden full of leavs -> garden full of leaves (correct: garden full of leaves )\n",
      "hits = 10\n",
      "\n",
      "================ 18 ===================\n",
      "Error: manger\n",
      "Candidates: ['manager', 'managers', 'danger', 'managed', 'manger', 'manage', 'finger', 'dangers', 'monger', 'matter']\n",
      "Correction: manager\n",
      "talk to the manger -> talk to the manager (correct: talk to the manager )\n",
      "hits = 11\n",
      "\n",
      "================ 19 ===================\n",
      "Error: aero\n",
      "Candidates: ['area', 'are', 'were', 'air', 'her', 'aaron', 'hero', 'here', 'apron', 'also']\n",
      "Correction: hero\n",
      "they throw a aero -> they throw a hero (correct: they throw a arrow )\n",
      "hits = 11\n",
      "\n",
      "================ 20 ===================\n",
      "Error: ansion\n",
      "Candidates: ['union', 'action', 'unison', 'onion', 'ention', 'anton', 'anon', 'arson', 'ensign', 'angio']\n",
      "Correction: action\n",
      "an ansion method of hunting -> an action method of hunting (correct: an ancient method of hunting )\n",
      "hits = 11\n",
      "\n",
      "Precision: 0.55\n",
      "FalseAlarm: 0.45\n"
     ]
    }
   ],
   "source": [
    "# lines = ['I was on an exclation \tI was on an escalator', 'to tidy up his gardon \tto tidy up his garden','talk to the manger \ttalk to the manager', 'through the fance \tthrough the fence']\n",
    "\n",
    "cor, hits = 0, 0\n",
    "lines = open('lab4.test.1.txt', 'r', encoding='utf8').readlines()[:20]\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "# for line in lines:\n",
    "    print(\"================\", i+1, \"===================\")\n",
    "    wrong, right = line.split('\\t')\n",
    "\n",
    "    tokens = wrong.strip().split(' ') # words(open('big.txt').read())) # or using regex\n",
    "    lowest_pair, lowest_pos = get_lowest_tri(tokens)\n",
    "    \n",
    "    sent, error_word, right_word, candidates, _ = get_max_sent(tokens, lowest_pos)\n",
    "    sent, wrong, right = ' '.join(sent).strip(), wrong.strip(), right.strip()\n",
    "    \n",
    "    if sent == right: hits += 1\n",
    "    cor += 1\n",
    "    \n",
    "    print(\"Error:\", error_word)\n",
    "    print(\"Candidates:\", candidates)\n",
    "    print(\"Correction:\", right_word)\n",
    "    print(wrong, \"->\", sent, \"(correct:\", right, \")\")\n",
    "    print(\"hits =\", hits)\n",
    "    print()\n",
    "\n",
    "print(\"Precision:\", hits/cor)\n",
    "print(\"FalseAlarm:\", (cor-hits)/cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
