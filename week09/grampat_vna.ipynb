{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from akl import akl\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "#from pgrules import isverbpat\n",
    "\n",
    "pgPreps = 'in_favor_of|_|about|after|against|among|as|at|between|behind|by|for|from|in|into|of|on|upon|over|through|to|toward|towarV in favour of\truled in favour ofV in favour of\truled in favour ofds|with'.split('|')\n",
    "otherPreps ='out|down'.split('|')\n",
    "verbpat = ('V; V n; V ord; V oneself; V adj; V -ing; V to v; V v; V that; V wh; V wh to v; V quote; '+\\\n",
    "              'V so; V not; V as if; V as though; V someway; V together; V as adj; V as to wh; V by amount; '+\\\n",
    "              'V amount; V by -ing; V in favour of n; V in favour of ing; V n in favour of n; V n in favour of ing; V n n; V n adj; V n -ing; V n to v; V n v n; V n that; '+\\\n",
    "              'V n wh; V n wh to v; V n quote; V n v-ed; V n someway; V n with together; '+\\\n",
    "              'V n as adj; V n into -ing; V adv; V and v').split('; ')\n",
    "verbpat += ['V %s n' % prep for prep in pgPreps]+['V n %s n' % prep for prep in verbpat]\n",
    "verbpat += [pat.replace('V ', 'V-ed ') for pat in verbpat]\n",
    "\n",
    "pgNoun = ('N for n to v; N from n that; N from n to v; N from n for n; N in favor of; N in favour of; '+\\\n",
    "            'N of amount; N of n as n; N of n to n; N of n with n; N on n for n; N on n to v'+\\\n",
    "            'N that; N to v; N to n that; N to n to v; N with n for n; N with n that; N with n to v').split('; ')\n",
    "pgNoun += pgNoun + ['N %s -ing' % prep for prep in pgPreps ]\n",
    "pgNoun += pgNoun + ['ADJ %s n' % prep for prep in pgPreps if prep != 'of']+ ['N %s -ing' % prep for prep in pgPreps]\n",
    "pgAdj = ('ADJ adj; ADJ and adj; ADJ as to wh; '+\\\n",
    "        'ADJ enough; ADJ enough for n; ADJ enough for n to v; ADJ enough n; '+\\\n",
    "        'ADJ enough n for n; ADJ enough n for n to v; ADJ enough n that; ADJ enough to v; '+\\\n",
    "        'ADJ for n to v; ADJ from n to n; ADJ in color; ADJ -ing; '+\\\n",
    "        'ADJ in n as n; ADJ in n from n; ADJ in n to n; ADJ in n with n; ADJ in n as n; ADJ n for n'+\\\n",
    "        'ADJ n to v; ADJ on n for n; ADJ on n to v; ADJ that; ADJ to v; ADJ to n for n; ADJ n for -ing'+\\\n",
    "        'ADJ wh; ADJ on n for n; ADJ on n to v; ADJ that; ADJ to v; ADJ to n for n; ADJ n for -ing').split('; ')\n",
    "pgAdj += [ 'ADJ %s n'%prep for prep in pgPreps ]\n",
    "pgPatterns = verbpat + pgAdj + pgNoun\n",
    "\n",
    "reservedWords = 'how wh; who wh; what wh; when wh; someway someway; together together; that that'.split('; ')\n",
    "pronOBJ = ['me', 'us', 'you', 'him', 'them']\n",
    "\n",
    "# defaultMap = {'NP': 'n', 'VP': 'v', 'JP': 'adj', 'ADJP': 'adj', 'ADVP': 'adv', 'SBAR': 'that', }\n",
    "# selfWords = ['myself', 'ourselves', 'yourself', 'himself', 'herself', 'themselves']\n",
    "# pronOBJ = ['me', 'us', 'you', 'him', 'them']\n",
    "# ordWords = ['first', 'second', 'third', 'fourth', 'fifth', 'sixth', 'seventh', 'eighth', 'nineth', 'tenth']\n",
    "# reversedWords = ['so', 'not', 'though', 'if', 'someway', 'together', 'way', 'favor', 'favour', 'as if', 'as though']\n",
    "# whWords = ['who', 'what', 'when', 'where', 'whether']\n",
    "\n",
    "mapHead = dict( [('H-NP', 'N'), ('H-VP', 'V'), ('H-ADJP', 'ADJ'), ('H-ADVP', 'ADV'), ('H-VB', 'V')] )\n",
    "#mapRest = dict( [('H-NP', 'n'), ('H-VP', 'v'), ('H-TO', 'to'), ('H-ADJ', 'adj'), ('H-ADV', 'adv')] )\n",
    "mapRest = dict( [('VBG', 'ing'), ('VBD', 'v-ed'), ('VBN', 'v-ed'), ('VB', 'v'), ('NN', 'n'), ('NNS', 'n'), ('JJ', 'adj'), ('RB', 'adv')] )\n",
    "mapRW = dict( [ pair.split() for pair in reservedWords ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all that remains for me to do is to say good-bye .\n",
      "REMAIN-V\tV for n\tall that remains for me to do is to say good-bye .\n",
      "BE-V\tV to v\tall that remains for me to do is to say good-bye .\n",
      "\n",
      "all the commune members , young and old , went out to hervest the crops .\n",
      "\n",
      "as soon as they finish the new businese administration building , our offices are going to be moved .\n",
      "\n",
      "beautiful though the necklace was , we thought it was over-priced so we did n't buy it .\n",
      "BE-V\tV\tbeautiful though the necklace was , we thought it was over-priced so we did n't buy it .\n",
      "BE-V\tV adj\tbeautiful though the necklace was , we thought it was over-priced so we did n't buy it .\n",
      "\n",
      "by the end of last year , we had learned over 2 , 000 English words and phrases .\n",
      "\n",
      "he has sold his house and a lot of furniture in it .\n",
      "\n",
      "he is a friend of mine . ( he is one of my friends . )\n",
      "BE-V\tV n\the is a friend of mine . ( he is one of my friends . )\n",
      "BE-V\tV n\the is a friend of mine . ( he is one of my friends . )\n",
      "\n",
      "he is not concerned with the difficulties of the factory at all .\n",
      "CONCERN-V\tV with n\the is not concerned with the difficulties of the factory at all .\n",
      "\n",
      "his English was good enough for him to pass the TOEFL .\n",
      "BE-V\tV adv\this English was good enough for him to pass the TOEFL .\n",
      "\n",
      "I arrived early in order that I might not miss anything .\n",
      "\n",
      "I met Lao Wang as soon as I went out of the door .\n",
      "\n",
      "I 'll finish working at 5 : 30 and get home by 6 o'clock .\n",
      "\n",
      "in this country the old get well cared and the young well educated .\n",
      "\n",
      "it 's my father who came here to look for me this morning .\n",
      "\n",
      "it 's the only building I 've ever seen which is made entirely of glass .\n"
     ]
    }
   ],
   "source": [
    "maxDegree = 9\n",
    "\n",
    "def sentence_to_ngram(words, lemmas, tags, chunks): \n",
    "    return [ (k, k+degree) for k in range(1,len(words)) for degree in range(2, min(maxDegree, len(words)-k+1)) ]\n",
    "    #                 if chunks[k][-1] in ['H-VP', 'H-NP', 'H-ADJP'] \n",
    "    #                 and chunks[k+degree-1][-1] in ['H-VP', 'H-NP', 'H-ADJP', 'H-ADVP'] ]\n",
    "\n",
    "    \n",
    "def hasTwoObjs(tag, chunk):\n",
    "    if chunk[-1] != 'H-NP': return False\n",
    "    return (len(tag) > 1 and tag[0] in pronOBJ) or (len(tag) > 1 and 'DT' in tag[1:])\n",
    "    \n",
    "\n",
    "# amount / enough / \n",
    "def chunk_to_element(words, lemmas, tags, chunks, i, isHead):\n",
    "    #print ('***', i, words[i], lemmas[i], tags[i], chunks[i], isHead, tags[i][-1] == 'RP' and tags[i-1][-1][:2] == 'VB')\n",
    "\n",
    "    # catch map['H-VP'] => 'V'\n",
    "    if isHead:                                                          \n",
    "        return mapHead[chunks[i][-1]] if chunks[i][-1] in mapHead else '*'\n",
    "    \n",
    "    if lemmas[i][0] == 'favour' and words[i-1][-1]=='in' and words[i+1][0]=='of': \n",
    "        return 'favour'\n",
    "    \n",
    "    if tags[i][-1] == 'RP' and tags[i-1][-1][:2] == 'VB':                \n",
    "        return '_'\n",
    "    \n",
    "    # catch what / who / someway / that\n",
    "    if tags[i][0][0]=='W' and lemmas[i][-1] in mapRW:                    \n",
    "        return mapRW[lemmas[i][-1]]\n",
    "    \n",
    "    if hasTwoObjs(tags[i], chunks[i]):                                              \n",
    "        return 'n n'\n",
    "    \n",
    "    # map to V-ed / ing\n",
    "    if tags[i][-1] in mapRest:                            \n",
    "        return mapRest[tags[i][-1]]\n",
    "    if tags[i][-1][:2] in mapRest:                        \n",
    "        return mapRest[tags[i][-1][:2]]\n",
    "    \n",
    "    # H-NP -> N -> n\n",
    "    if chunks[i][-1] in mapHead:                            \n",
    "        return mapHead[chunks[i][-1]].lower()\n",
    "    \n",
    "    if lemmas[i][-1] in pgPreps:                                         \n",
    "        return lemmas[i][-1]\n",
    "    \n",
    "    return lemmas[i][-1] # return '.'\n",
    "\n",
    "def simplifyPat(pat): \n",
    "    if pat == 'V ,':   return 'V'\n",
    "    elif pat == 'N ,': return 'N' # ???\n",
    "    else: return pat.replace(' _', '').replace('_', ' ').replace('  ', ' ')\n",
    "    \n",
    "def isPat(pat):\n",
    "    return pat in pgPatterns\n",
    "\n",
    "def ngram_to_pat(words, lemmas, tags, chunks, start, end):\n",
    "    pat, doneHead = [], False\n",
    "    \n",
    "    for i in range(start, end):\n",
    "        isHead = tags[i][-1][0] in ['V', 'N', 'J'] and not doneHead # 看第一個 char is V?\n",
    "        pat.append( chunk_to_element(words, lemmas, tags, chunks, i, isHead) )\n",
    "        \n",
    "        # 就算 True 了還是繼續跑Ｒ，用意在？\n",
    "        if isHead: doneHead = True\n",
    "\n",
    "    pat = simplifyPat(' '.join(pat))\n",
    "    return pat if isPat(pat) else ''\n",
    "\n",
    "\n",
    "def ngram_to_head(words, lemmas, tags, chunks, start, end):\n",
    "    for i in range(start, end):\n",
    "        if tags[i][-1][0] in 'V' and tags[i+1][-1]=='RP':  \n",
    "            return lemmas[i][-1].upper()+ ('_'+lemmas[i+1][-1].upper())\n",
    "        if tags[i][-1][0] in ['V', 'N', 'J']:  \n",
    "            return lemmas[i][-1].upper()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    for line in open('test.txt', 'r', encoding='utf8'):\n",
    "#     for line in sys.stdin:\n",
    "#     for line in open('UM-Corpus.en.200k.tagged.txt', 'r', encoding='utf8'):\n",
    "        \n",
    "        parse = eval(line.strip())\n",
    "        parse = [ [y.split() for y in x]  for x in parse ]\n",
    "\n",
    "        sent = ' '.join([' '.join(x) for x in parse[0] ])\n",
    "        print ('\\n' + sent)\n",
    "        for start, end in sentence_to_ngram(*parse): # [ (1, 3), (1, 4) ... ]\n",
    "            pat = ngram_to_pat(*parse, start, end)\n",
    "            if pat:\n",
    "                pos = pat.split(' ')[0]\n",
    "                head = ngram_to_head(*parse, start, end)\n",
    "\n",
    "                if (head+'-'+pos).lower() in akl:\n",
    "                    print ('%s\\t%s\\t%s' % (head+'-'+pos, pat, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
