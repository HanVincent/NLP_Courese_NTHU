{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import wordnet as wn\n",
    "import re\n",
    "from pprint import pprint\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "import nltk, random\n",
    "from nltk.probability import DictionaryProbDist as D\n",
    "\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def wnTag(pos): return {'noun': 'n', 'verb': 'v', 'adjective': 'a', 'adverb': 'r'}[pos]\n",
    "\n",
    "TF = defaultdict(lambda: Counter())\n",
    "DF = defaultdict(lambda: [])\n",
    "\n",
    "\n",
    "def split_col(data):\n",
    "    training = [  line.strip().split('\\t') for line in data if line.strip() != '' ]\n",
    "    return training\n",
    "\n",
    "\n",
    "def isHead(head, word, tag):\n",
    "    try:\n",
    "        return lmtzr.lemmatize(word, tag) == head\n",
    "    except:\n",
    "        return False\n",
    "        \n",
    "    \n",
    "def set_TF_DF(training):   \n",
    "    for wnid, wncat, senseDef, target in training:\n",
    "        head, pos = wnid.split('-')[:2]\n",
    "        for word in words(senseDef):\n",
    "            if word != head and not isHead(head, word, pos):\n",
    "                TF[word][wncat] += 1\n",
    "                DF[word] += [] if wncat in DF[word] else [wncat]   \n",
    "    \n",
    "    \n",
    "def gender_features(wnid, wncat, senseDef, target):\n",
    "    head, pos = wnid.split('-')[:2]\n",
    "    features = {'pos': pos}\n",
    "    for word in words(senseDef):\n",
    "        if word != head and not isHead(head, word, pos): # 有需要過濾自己嗎？\n",
    "            for cat, count in TF[word].most_common(3):\n",
    "                features.update({cat: count / len(DF[word])}) # tf*int(1000/df)\n",
    "    return (features, wncat)\n",
    "    \n",
    "    \n",
    "def LG_gender(train_set, test_set, origin_test=None):\n",
    "    print('== SkLearn MaxEnt ==')\n",
    "    \n",
    "    from nltk.classify import SklearnClassifier \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    sklearn_classifier = SklearnClassifier(LogisticRegression(C=10e5)).train(train_set)\n",
    "    return sklearn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== SkLearn MaxEnt ==\n",
      "0.15625\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "if __name__ == '__main__':\n",
    "    data = open('wn.in.evp.cat.txt', 'r').readlines()\n",
    "#     random.shuffle(data)\n",
    "    split_point = len(data)*9//10\n",
    "    train_set, test_set = data[:split_point], data[split_point:]\n",
    "\n",
    "    training = split_col(train_set)\n",
    "    testing = split_col(test_set)\n",
    "    set_TF_DF(training)\n",
    "    \n",
    "#     pprint(gender_features(*training[0])) # 看 feature\n",
    "    \n",
    "    train_featuresets = [ gender_features(*x) for x in training ]\n",
    "    test_featuresets = [ gender_features(*x) for x in testing ]\n",
    "    sklearn_classifier = LG_gender(train_featuresets, test_featuresets)\n",
    " \n",
    "\n",
    "    print(nltk.classify.accuracy(sklearn_classifier, test_featuresets)) # 未過濾\n",
    "    \n",
    "\n",
    "    correct = 0\n",
    "    for i, (feature, label) in enumerate(test_featuresets):\n",
    "        prob_dict = sklearn_classifier.prob_classify(test_featuresets[i][0])._prob_dict\n",
    "\n",
    "        targets = json.loads(testing[i][3].replace(\"'\", '\"')).values()\n",
    "        probs = [(target, prob_dict[target]) for target in targets if target in prob_dict]\n",
    "        if not probs:\n",
    "            if max(prob_dict.items(), key=lambda x: x[1])[0] == label:\n",
    "                correct+=1\n",
    "        else: \n",
    "            if max(probs, key=lambda x: x[1])[0] == label:\n",
    "                correct+=1\n",
    "    print(correct/len(test_featuresets))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
